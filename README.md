# Panoptic-Vision-Unveiling-Features-in-360-



## Objectives

The central aim of our project is to implement a robust framework for feature detection and segmentation specifically tailored for omnidirectional images. This comprehensive approach involves leveraging established techniques in feature extraction and segmentation to enhance our understanding of complex visual content in panoramic views.

### SIFT and SURF Feature Extraction:

Our strategy incorporates well-established techniques such as Scale-Invariant Feature Transform (SIFT) and Speeded Up Robust Features (SURF) for precise feature extraction in omnidirectional images. These methods enable us to identify distinctive features, irrespective of scale or orientation, contributing to a more nuanced analysis of the intricate content within the panoramic view.

### Undistort Algorithm for Enhanced Analysis:
To facilitate a more accessible analysis of omnidirectional images, we've integrated an Undistort Algorithm. This algorithm plays a crucial role in transforming omnidirectional images into a 2D layout and equirectangular format, reducing complexities associated with equirectangular distortions. This transformation serves as a foundational step for feature detection and analysis.

### Objective Feature Detection Using YOLO-NAS:
In our pursuit of precise feature detection, we've implemented the You Only Look Once Neural Architecture Search (YOLO-NAS) network. This sophisticated deep learning model enhances our ability to identify and accurately locate objects within equirectangular images, providing a robust foundation for feature detection in panoramic views.

### Semantic Segmentation for Enhanced Feature Analysis:
To deepen our understanding of features within omnidirectional images, we've employed the "Segment Anything" model for semantic segmentation. This approach categorizes and isolates features within the images, offering a more profound insight into their structural and contextual attributes. This semantic segmentation contributes significantly to the overall analysis of key features in omnidirectional views.

Our project's focus on feature detection and segmentation in omnidirectional images is designed to offer advanced capabilities in understanding complex visual information. 
This approach aims to enhance applications such as immersive virtual reality experiences, panoramic surveillance, and robotic navigation in diverse and dynamic environments.
